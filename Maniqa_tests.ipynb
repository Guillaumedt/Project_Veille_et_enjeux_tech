{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://github.com/IIGROUP/MANIQA/blob/master/models/maniqa.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Block\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SwinTransformer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from timm.models.vision_transformer import Block\n",
    "from models.swin import SwinTransformer\n",
    "from torch import nn\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TABlock(nn.Module):\n",
    "    def __init__(self, dim, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.c_q = nn.Linear(dim, dim)\n",
    "        self.c_k = nn.Linear(dim, dim)\n",
    "        self.c_v = nn.Linear(dim, dim)\n",
    "        self.norm_fact = dim ** -0.5\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.proj_drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x\n",
    "        B, C, N = x.shape\n",
    "        q = self.c_q(x)\n",
    "        k = self.c_k(x)\n",
    "        v = self.c_v(x)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) * self.norm_fact\n",
    "        attn = self.softmax(attn)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, C, N)\n",
    "        x = self.proj_drop(x)\n",
    "        x = x + _x\n",
    "        return x\n",
    "\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    \n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        self.outputs.append(module_out)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "\n",
    "\n",
    "class MANIQA(nn.Module):\n",
    "    def __init__(self, embed_dim=72, num_outputs=1, patch_size=8, drop=0.1, \n",
    "                    depths=[2, 2], window_size=4, dim_mlp=768, num_heads=[4, 4],\n",
    "                    img_size=224, num_tab=2, scale=0.8, **kwargs):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.input_size = img_size // patch_size\n",
    "        self.patches_resolution = (img_size // patch_size, img_size // patch_size)\n",
    "        \n",
    "        self.vit = timm.create_model('vit_base_patch8_224', pretrained=True)\n",
    "        self.save_output = SaveOutput()\n",
    "        hook_handles = []\n",
    "        for layer in self.vit.modules():\n",
    "            if isinstance(layer, Block):\n",
    "                handle = layer.register_forward_hook(self.save_output)\n",
    "                hook_handles.append(handle)\n",
    "\n",
    "        self.tablock1 = nn.ModuleList()\n",
    "        for i in range(num_tab):\n",
    "            tab = TABlock(self.input_size ** 2)\n",
    "            self.tablock1.append(tab)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(embed_dim * 4, embed_dim, 1, 1, 0)\n",
    "        self.swintransformer1 = SwinTransformer(\n",
    "            patches_resolution=self.patches_resolution,\n",
    "            depths=depths,\n",
    "            num_heads=num_heads,\n",
    "            embed_dim=embed_dim,\n",
    "            window_size=window_size,\n",
    "            dim_mlp=dim_mlp,\n",
    "            scale=scale\n",
    "        )\n",
    "\n",
    "        self.tablock2 = nn.ModuleList()\n",
    "        for i in range(num_tab):\n",
    "            tab = TABlock(self.input_size ** 2)\n",
    "            self.tablock2.append(tab)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(embed_dim, embed_dim // 2, 1, 1, 0)\n",
    "        self.swintransformer2 = SwinTransformer(\n",
    "            patches_resolution=self.patches_resolution,\n",
    "            depths=depths,\n",
    "            num_heads=num_heads,\n",
    "            embed_dim=embed_dim // 2,\n",
    "            window_size=window_size,\n",
    "            dim_mlp=dim_mlp,\n",
    "            scale=scale\n",
    "        )\n",
    "        \n",
    "        self.fc_score = nn.Sequential(\n",
    "            nn.Linear(embed_dim // 2, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(embed_dim // 2, num_outputs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_weight = nn.Sequential(\n",
    "            nn.Linear(embed_dim // 2, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(embed_dim // 2, num_outputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def extract_feature(self, save_output):\n",
    "        x6 = save_output.outputs[6][:, 1:]\n",
    "        x7 = save_output.outputs[7][:, 1:]\n",
    "        x8 = save_output.outputs[8][:, 1:]\n",
    "        x9 = save_output.outputs[9][:, 1:]\n",
    "        x = torch.cat((x6, x7, x8, x9), dim=2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = self.vit(x)\n",
    "        x = self.extract_feature(self.save_output)\n",
    "        self.save_output.outputs.clear()\n",
    "\n",
    "        # stage 1\n",
    "        x = rearrange(x, 'b (h w) c -> b c (h w)', h=self.input_size, w=self.input_size)\n",
    "        for tab in self.tablock1:\n",
    "            x = tab(x)\n",
    "        x = rearrange(x, 'b c (h w) -> b c h w', h=self.input_size, w=self.input_size)\n",
    "        x = self.conv1(x)\n",
    "        x = self.swintransformer1(x)\n",
    "\n",
    "        # stage2\n",
    "        x = rearrange(x, 'b c h w -> b c (h w)', h=self.input_size, w=self.input_size)\n",
    "        for tab in self.tablock2:\n",
    "            x = tab(x)\n",
    "        x = rearrange(x, 'b c (h w) -> b c h w', h=self.input_size, w=self.input_size)\n",
    "        x = self.conv2(x)\n",
    "        x = self.swintransformer2(x)\n",
    "\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c', h=self.input_size, w=self.input_size)\n",
    "        score = torch.tensor([]).cuda()\n",
    "        for i in range(x.shape[0]):\n",
    "            f = self.fc_score(x[i])\n",
    "            w = self.fc_weight(x[i])\n",
    "            _s = torch.sum(f * w) / torch.sum(w)\n",
    "            score = torch.cat((score, _s.unsqueeze(0)), 0)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Charger et prétraiter l'image\n",
    "path = \"chemin_vers_votre_image.jpg\"\n",
    "img = Image.open(path).convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "img = transform(img)\n",
    "img = img.unsqueeze(0)  # Ajouter une dimension de lot (batch dimension)\n",
    "\n",
    "# Charger le modèle\n",
    "model = MANIQA()\n",
    "model = model.cuda()  # Si le modèle est sur GPU\n",
    "\n",
    "# Mettre le modèle en mode évaluation\n",
    "model.eval()\n",
    "\n",
    "# Passer l'image à travers le modèle\n",
    "with torch.no_grad():\n",
    "    img = img.cuda()  # Si l'image est sur GPU\n",
    "    output = model(img)\n",
    "\n",
    "# Le score pour l'image donnée\n",
    "print(\"Score:\", output.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
